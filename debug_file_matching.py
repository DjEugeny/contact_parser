#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç –°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —Ñ–∞–π–ª–æ–≤
"""

import re
from pathlib import Path
from typing import List, Dict, Set
from src.file_utils import normalize_filename

# –§—É–Ω–∫—Ü–∏—è normalize_filename –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑ src.file_utils

def analyze_file_matching(date: str):
    """üìä –ê–Ω–∞–ª–∏–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç—ã"""
    
    attachments_dir = Path(f"/Users/evgenyzach/contact_parser/data/attachments/{date}")
    results_dir = Path(f"/Users/evgenyzach/contact_parser/data/final_results/texts/{date}")
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–∞—Ç—ã: {date}")
    print("=" * 60)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ attachments
    if not attachments_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {attachments_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    attachment_files = []
    for ext in ['*.pdf', '*.docx', '*.doc', '*.xlsx', '*.xls', '*.png', '*.jpg', '*.jpeg', '*.tiff']:
        attachment_files.extend(attachments_dir.glob(ext))
    
    print(f"üìÅ –§–∞–π–ª—ã –≤ attachments ({len(attachment_files)}):")
    for i, file_path in enumerate(attachment_files, 1):
        print(f"  {i:2d}. {file_path.name}")
    
    print()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    result_files = []
    if results_dir.exists():
        result_files = list(results_dir.glob('*.txt'))
    
    print(f"üìÑ –§–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ({len(result_files)}):")
    for i, file_path in enumerate(result_files, 1):
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_name = file_path.stem.split('___')[0]
        print(f"  {i:2d}. {result_name} -> {file_path.name}")
    
    print()
    print("üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
    print("-" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    processed_stems = set()
    processed_normalized = set()
    
    for result_file in result_files:
        result_stem = result_file.stem.split('___')[0]
        processed_stems.add(result_stem)
        processed_normalized.add(normalize_filename(result_stem))
    
    unprocessed_files = []
    
    for attachment_file in attachment_files:
        file_stem = attachment_file.stem
        normalized_stem = normalize_filename(file_stem)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        exact_match = file_stem in processed_stems
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        normalized_match = normalized_stem in processed_normalized
        
        status = "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω" if (exact_match or normalized_match) else "‚ùå –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω"
        
        print(f"  {status}: {attachment_file.name}")
        print(f"    –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è: '{file_stem}'")
        print(f"    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ: '{normalized_stem}'")
        print(f"    –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {exact_match}")
        print(f"    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {normalized_match}")
        
        if not (exact_match or normalized_match):
            unprocessed_files.append(attachment_file)
        
        print()
    
    print("üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ attachments: {len(attachment_files)}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(result_files)}")
    print(f"  –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(unprocessed_files)}")
    
    if unprocessed_files:
        print("\n‚ùå –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        for i, file_path in enumerate(unprocessed_files, 1):
            print(f"  {i}. {file_path.name}")
    
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏–º–µ–Ω–∞—Ö
    print("üîç –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
    print("-" * 40)
    
    normalized_groups = {}
    for attachment_file in attachment_files:
        normalized = normalize_filename(attachment_file.stem)
        if normalized not in normalized_groups:
            normalized_groups[normalized] = []
        normalized_groups[normalized].append(attachment_file.name)
    
    for normalized, files in normalized_groups.items():
        if len(files) > 1:
            print(f"  –ì—Ä—É–ø–ø–∞ '{normalized}':")
            for file in files:
                print(f"    - {file}")
            print()

if __name__ == "__main__":
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—É—é –¥–∞—Ç—É
    analyze_file_matching("2025-07-29")