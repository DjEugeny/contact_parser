#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º–æ–¥—É–ª—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ü–µ–ø–æ—á–∫–∞—Ö –ø–µ—Ä–µ—Å—ã–ª–æ–∫ –∏ –±–æ–ª—å—à–∏—Ö –ø–∏—Å—å–º–∞—Ö
"""

import re
from typing import List, Dict, Set, Tuple
from difflib import SequenceMatcher
from collections import defaultdict


class AdvancedContactDeduplicator:
    """üîß –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self):
        self.similarity_threshold = 0.75  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –∏–º–µ–Ω (–ø–æ–Ω–∏–∂–µ–Ω)
        self.phone_similarity_threshold = 0.9  # –ü–æ—Ä–æ–≥ –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
        
    def deduplicate_contacts(self, contacts: List[Dict]) -> List[Dict]:
        """üéØ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Å –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
        if not contacts:
            return []
            
        print(f"   üîç –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è {len(contacts)} –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
        
        # –≠—Ç–∞–ø 0: –ê–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–µ–∫ –ø–µ—Ä–µ—Å—ã–ª–æ–∫ –∏ —É–¥–∞–ª–µ–Ω–∏–µ —è–≤–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        forward_cleaned = self._clean_forward_chain_duplicates(contacts)
        
        # –≠—Ç–∞–ø 1: –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ email/—Ç–µ–ª–µ—Ñ–æ–Ω—É
        exact_groups = self._group_by_exact_matches(forward_cleaned)
        
        # –≠—Ç–∞–ø 2: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∏–º–µ–Ω–∞–º
        semantic_groups = self._group_by_semantic_similarity(exact_groups)
        
        # –≠—Ç–∞–ø 3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        unique_contacts = self._merge_contact_groups(semantic_groups)
        
        duplicates_removed = len(contacts) - len(unique_contacts)
        if duplicates_removed > 0:
            print(f"   ‚úÖ –£–¥–∞–ª–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º)")
            print(f"   üìä –ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {len(unique_contacts)}")
        
        return unique_contacts
    
    def _group_by_exact_matches(self, contacts: List[Dict]) -> List[List[Dict]]:
        """üìß –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–æ—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º email/—Ç–µ–ª–µ—Ñ–æ–Ω–∞"""
        email_groups = defaultdict(list)
        phone_groups = defaultdict(list)
        ungrouped = []
        
        for contact in contacts:
            email = self._normalize_email(contact.get('email', ''))
            phone = self._normalize_phone(contact.get('phone', ''))
            
            grouped = False
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ email (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1)
            if email:
                email_groups[email].append(contact)
                grouped = True
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2), –µ—Å–ª–∏ –Ω–µ—Ç email
            elif phone and len(phone) > 6:
                phone_groups[phone].append(contact)
                grouped = True
            
            if not grouped:
                ungrouped.append(contact)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã
        groups = []
        groups.extend([group for group in email_groups.values() if len(group) > 0])
        groups.extend([group for group in phone_groups.values() if len(group) > 0])
        groups.extend([[contact] for contact in ungrouped])  # –û–¥–∏–Ω–æ—á–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        
        return groups
    
    def _group_by_semantic_similarity(self, groups: List[List[Dict]]) -> List[List[Dict]]:
        """üß† –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É –∏–º–µ–Ω –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π"""
        final_groups = []
        
        for group in groups:
            if len(group) == 1:
                final_groups.append(group)
                continue
            
            # –î–ª—è –≥—Ä—É–ø–ø —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏ –∏—â–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
            subgroups = self._find_semantic_duplicates(group)
            final_groups.extend(subgroups)
        
        return final_groups
    
    def _find_semantic_duplicates(self, contacts: List[Dict]) -> List[List[Dict]]:
        """üîç –ü–æ–∏—Å–∫ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        if len(contacts) <= 1:
            return [contacts]
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–∂–µ—Å—Ç–∏
        similarity_matrix = []
        for i, contact1 in enumerate(contacts):
            row = []
            for j, contact2 in enumerate(contacts):
                if i == j:
                    row.append(1.0)
                else:
                    similarity = self._calculate_contact_similarity(contact1, contact2)
                    row.append(similarity)
            similarity_matrix.append(row)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
        groups = []
        used_indices = set()
        
        for i in range(len(contacts)):
            if i in used_indices:
                continue
            
            group = [contacts[i]]
            used_indices.add(i)
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã
            for j in range(i + 1, len(contacts)):
                if j in used_indices:
                    continue
                
                if similarity_matrix[i][j] >= self.similarity_threshold:
                    group.append(contacts[j])
                    used_indices.add(j)
            
            groups.append(group)
        
        return groups
    
    def _calculate_contact_similarity(self, contact1: Dict, contact2: Dict) -> float:
        """üìä –†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏"""
        scores = []
        
        # –°—Ö–æ–∂–µ—Å—Ç—å –∏–º–µ–Ω (–≤–µ—Å 50%) - —É–≤–µ–ª–∏—á–µ–Ω –≤–µ—Å
        name1 = self._normalize_name(contact1.get('name', ''))
        name2 = self._normalize_name(contact2.get('name', ''))
        if name1 and name2:
            name_similarity = self._calculate_name_similarity(name1, name2)
            scores.append(('name', name_similarity, 0.5))
        
        # –°—Ö–æ–∂–µ—Å—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π (–≤–µ—Å 25%)
        org1 = self._normalize_name(contact1.get('organization', ''))
        org2 = self._normalize_name(contact2.get('organization', ''))
        if org1 and org2:
            org_similarity = self._calculate_organization_similarity(org1, org2)
            scores.append(('org', org_similarity, 0.25))
        
        # –°—Ö–æ–∂–µ—Å—Ç—å –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π (–≤–µ—Å 15%)
        pos1 = self._normalize_name(contact1.get('position', ''))
        pos2 = self._normalize_name(contact2.get('position', ''))
        if pos1 and pos2:
            pos_similarity = SequenceMatcher(None, pos1, pos2).ratio()
            scores.append(('position', pos_similarity, 0.15))
        
        # –°—Ö–æ–∂–µ—Å—Ç—å –≥–æ—Ä–æ–¥–æ–≤ (–≤–µ—Å 10%)
        city1 = self._normalize_name(contact1.get('city', ''))
        city2 = self._normalize_name(contact2.get('city', ''))
        if city1 and city2:
            city_similarity = self._calculate_city_similarity(city1, city2)
            scores.append(('city', city_similarity, 0.1))
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
        if not scores:
            return 0.0
        
        total_weight = sum(weight for _, _, weight in scores)
        weighted_sum = sum(score * weight for _, score, weight in scores)
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0
    
    def _merge_contact_groups(self, groups: List[List[Dict]]) -> List[Dict]:
        """üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏"""
        unique_contacts = []
        
        for group in groups:
            if len(group) == 1:
                unique_contacts.append(group[0])
            else:
                merged_contact = self._merge_contact_group(group)
                unique_contacts.append(merged_contact)
        
        return unique_contacts
    
    def _merge_contact_group(self, contacts: List[Dict]) -> Dict:
        """üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –æ–¥–∏–Ω –∫–æ–Ω—Ç–∞–∫—Ç"""
        if not contacts:
            return {}
        
        if len(contacts) == 1:
            return contacts[0]
        
        print(f"   üîó –û–±—ä–µ–¥–∏–Ω—è—é {len(contacts)} —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
        
        # –ë–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–∞–∫—Ç - –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π
        base_contact = max(contacts, key=lambda c: self._calculate_contact_completeness(c))
        merged = base_contact.copy()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        all_emails = set()
        all_phones = set()
        all_names = set()
        all_organizations = set()
        all_positions = set()
        all_cities = set()
        max_confidence = 0
        
        for contact in contacts:
            # –°–æ–±–∏—Ä–∞–µ–º emails
            if contact.get('email'):
                all_emails.add(contact['email'])
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            if contact.get('phone'):
                all_phones.add(contact['phone'])
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏–º–µ–Ω–∞
            if contact.get('name'):
                all_names.add(contact['name'])
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
            if contact.get('organization'):
                all_organizations.add(contact['organization'])
            
            # –°–æ–±–∏—Ä–∞–µ–º –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
            if contact.get('position'):
                all_positions.add(contact['position'])
            
            # –°–æ–±–∏—Ä–∞–µ–º –≥–æ—Ä–æ–¥–∞
            if contact.get('city'):
                all_cities.add(contact['city'])
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π confidence
            contact_conf = contact.get('confidence', 0)
            if contact_conf > max_confidence:
                max_confidence = contact_conf
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è
        if all_emails:
            merged['email'] = self._select_best_value(list(all_emails), 'email')
            if len(all_emails) > 1:
                merged['other_emails'] = [e for e in all_emails if e != merged['email']]
        
        if all_phones:
            merged['phone'] = self._select_best_value(list(all_phones), 'phone')
            if len(all_phones) > 1:
                merged['other_phones'] = [p for p in all_phones if p != merged['phone']]
        
        if all_names:
            merged['name'] = self._select_best_value(list(all_names), 'name')
        
        if all_organizations:
            merged['organization'] = self._select_best_value(list(all_organizations), 'organization')
        
        if all_positions:
            merged['position'] = self._select_best_value(list(all_positions), 'position')
        
        if all_cities:
            merged['city'] = self._select_best_value(list(all_cities), 'city')
        
        merged['confidence'] = max_confidence
        merged['merged_from_count'] = len(contacts)
        
        return merged
    
    def _calculate_contact_completeness(self, contact: Dict) -> int:
        """üìä –†–∞—Å—á–µ—Ç –ø–æ–ª–Ω–æ—Ç—ã –∫–æ–Ω—Ç–∞–∫—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π)"""
        fields = ['name', 'email', 'phone', 'organization', 'position', 'city']
        return sum(1 for field in fields if contact.get(field))
    
    def _select_best_value(self, values: List[str], field_type: str) -> str:
        """üéØ –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞"""
        if not values:
            return ''
        
        if len(values) == 1:
            return values[0]
        
        # –î–ª—è email –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π –∫–æ—Ä–æ—Ç–∫–∏–π (–æ–±—ã—á–Ω–æ –æ—Å–Ω–æ–≤–Ω–æ–π)
        if field_type == 'email':
            return min(values, key=len)
        
        # –î–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π (–Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π)
        if field_type == 'phone':
            return max(values, key=len)
        
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ (–Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ)
        return max(values, key=len)
    
    def _normalize_email(self, email: str) -> str:
        """üìß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è email –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not email:
            return ''
        return email.lower().strip()
    
    def _normalize_phone(self, phone: str) -> str:
        """üìû –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not phone:
            return ''
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ +
        normalized = re.sub(r'[^\d+]', '', phone)
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É: –µ—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 8, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ +7
        if normalized.startswith('8') and len(normalized) == 11:
            normalized = '+7' + normalized[1:]
        return normalized
    
    def _normalize_name(self, name: str) -> str:
        """üë§ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not name:
            return ''
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        normalized = ' '.join(name.lower().strip().split())
        # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –∏ —Ç–∏—Ç—É–ª—ã
        common_titles = ['–≥-–Ω', '–≥-–∂–∞', '–º—Ä', '–º—Å', '–¥—Ä', '–ø—Ä–æ—Ñ', '–∏–Ω–∂']
        words = normalized.split()
        filtered_words = [w for w in words if w not in common_titles]
        return ' '.join(filtered_words)
    
    def _calculate_name_similarity(self, name1: str, name2: str) -> float:
        """üë§ –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏–º–µ–Ω"""
        # –†–∞–∑–±–∏–≤–∞–µ–º –∏–º–µ–Ω–∞ –Ω–∞ —á–∞—Å—Ç–∏
        parts1 = name1.split()
        parts2 = name2.split()
        
        # –ï—Å–ª–∏ –æ–¥–Ω–æ –∏–∑ –∏–º–µ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω–∏—Ü–∏–∞–ª—ã
        if any(len(part) == 1 or (len(part) == 2 and part.endswith('.')) for part in parts1 + parts2):
            return self._compare_names_with_initials(parts1, parts2)
        
        # –û–±—ã—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        return SequenceMatcher(None, name1, name2).ratio()
    
    def _compare_names_with_initials(self, parts1: List[str], parts2: List[str]) -> float:
        """üî§ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–º–µ–Ω —Å —É—á–µ—Ç–æ–º –∏–Ω–∏—Ü–∏–∞–ª–æ–≤"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–Ω–∏—Ü–∏–∞–ª—ã
        normalized1 = [self._normalize_name_part(part) for part in parts1]
        normalized2 = [self._normalize_name_part(part) for part in parts2]
        
        matches = 0
        total_parts = max(len(normalized1), len(normalized2))
        
        for i in range(min(len(normalized1), len(normalized2))):
            part1 = normalized1[i]
            part2 = normalized2[i]
            
            # –ï—Å–ª–∏ –æ–¥–Ω–∞ –∏–∑ —á–∞—Å—Ç–µ–π - –∏–Ω–∏—Ü–∏–∞–ª
            if len(part1) == 1 or len(part2) == 1:
                if part1[0] == part2[0]:  # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –±—É–∫–≤—ã
                    matches += 1
            else:
                # –û–±—ã—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                if SequenceMatcher(None, part1, part2).ratio() > 0.8:
                    matches += 1
        
        return matches / total_parts if total_parts > 0 else 0.0
    
    def _normalize_name_part(self, part: str) -> str:
        """üî§ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ –∏–º–µ–Ω–∏"""
        # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏ –∏–∑ –∏–Ω–∏—Ü–∏–∞–ª–æ–≤
        normalized = part.replace('.', '').lower()
        return normalized
    
    def _calculate_organization_similarity(self, org1: str, org2: str) -> float:
        """üè¢ –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π"""
        # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        org1_clean = self._clean_organization_name(org1)
        org2_clean = self._clean_organization_name(org2)
        
        return SequenceMatcher(None, org1_clean, org2_clean).ratio()
    
    def _clean_organization_name(self, org_name: str) -> str:
        """üè¢ –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –æ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π"""
        # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è –∏ —Ñ–æ—Ä–º—ã —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        common_abbreviations = ['–æ–æ–æ', '–∑–∞–æ', '–æ–∞–æ', '–∏–ø', '–ø–∞–æ', '–∞–æ', '—Ç–æ–æ', '–ª—Ç–¥', 'ltd', 'llc', 'inc']
        words = org_name.lower().split()
        filtered_words = [w for w in words if w not in common_abbreviations]
        return ' '.join(filtered_words)
    
    def _calculate_city_similarity(self, city1: str, city2: str) -> float:
        """üåç –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –≥–æ—Ä–æ–¥–æ–≤"""
        # –°–ª–æ–≤–∞—Ä—å —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –≥–æ—Ä–æ–¥–æ–≤
        city_abbreviations = {
            '—Å–ø–±': '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥',
            '–ø–∏—Ç–µ—Ä': '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥',
            '–º—Å–∫': '–º–æ—Å–∫–≤–∞',
            '–µ–∫–±': '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥',
            '–Ω—Å–∫': '–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫'
        }
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –≥–æ—Ä–æ–¥–æ–≤
        city1_norm = city_abbreviations.get(city1.lower(), city1.lower())
        city2_norm = city_abbreviations.get(city2.lower(), city2.lower())
        
        return SequenceMatcher(None, city1_norm, city2_norm).ratio()
    
    def _clean_forward_chain_duplicates(self, contacts: List[Dict]) -> List[Dict]:
        """üìß –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ —Ü–µ–ø–æ—á–µ–∫ –ø–µ—Ä–µ—Å—ã–ª–æ–∫"""
        if len(contacts) <= 1:
            return contacts
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
        source_groups = defaultdict(list)
        no_source = []
        
        for contact in contacts:
            source = contact.get('source', '')
            if source:
                source_groups[source].append(contact)
            else:
                no_source.append(contact)
        
        cleaned_contacts = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        for source, group_contacts in source_groups.items():
            if len(group_contacts) > 1:
                # –ò—â–µ–º —Ç–æ—á–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                unique_in_source = self._remove_exact_duplicates_in_source(group_contacts)
                cleaned_contacts.extend(unique_in_source)
            else:
                cleaned_contacts.extend(group_contacts)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã –±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        cleaned_contacts.extend(no_source)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª—è–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã —Å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏
        signature_cleaned = self._remove_signature_duplicates(cleaned_contacts)
        
        removed_count = len(contacts) - len(signature_cleaned)
        if removed_count > 0:
            print(f"   üßπ –£–¥–∞–ª–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ —Ü–µ–ø–æ—á–µ–∫ –ø–µ—Ä–µ—Å—ã–ª–æ–∫")
        
        return signature_cleaned
    
    def _remove_exact_duplicates_in_source(self, contacts: List[Dict]) -> List[Dict]:
        """üîç –£–¥–∞–ª–µ–Ω–∏–µ —Ç–æ—á–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        unique_contacts = []
        seen_signatures = set()
        
        for contact in contacts:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∏—Å—å –∫–æ–Ω—Ç–∞–∫—Ç–∞
            signature = self._create_contact_signature(contact)
            
            if signature not in seen_signatures:
                seen_signatures.add(signature)
                unique_contacts.append(contact)
        
        return unique_contacts
    
    def _remove_signature_duplicates(self, contacts: List[Dict]) -> List[Dict]:
        """‚úÇÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏ –ø–æ–¥–ø–∏—Å—è–º–∏"""
        unique_contacts = []
        seen_signatures = set()
        
        for contact in contacts:
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –ø–æ–¥–ø–∏—Å—å –¥–ª—è –º–µ–∂–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            signature = self._create_extended_contact_signature(contact)
            
            if signature not in seen_signatures:
                seen_signatures.add(signature)
                unique_contacts.append(contact)
        
        return unique_contacts
    
    def _create_contact_signature(self, contact: Dict) -> str:
        """üîë –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–ø–∏—Å–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        email = self._normalize_email(contact.get('email', ''))
        phone = self._normalize_phone(contact.get('phone', ''))
        name = self._normalize_name(contact.get('name', ''))
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ–¥–ø–∏—Å—å: email + —Ç–µ–ª–µ—Ñ–æ–Ω + –∏–º—è
        signature_parts = []
        
        if email:
            signature_parts.append(f"email:{email}")
        if phone and len(phone) > 6:
            signature_parts.append(f"phone:{phone}")
        if name:
            signature_parts.append(f"name:{name}")
        
        return "|".join(signature_parts)
    
    def _create_extended_contact_signature(self, contact: Dict) -> str:
        """üîë –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è –º–µ–∂–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        base_signature = self._create_contact_signature(contact)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –∏ –¥–æ–ª–∂–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        org = self._normalize_name(contact.get('organization', ''))
        position = self._normalize_name(contact.get('position', ''))
        
        extended_parts = [base_signature]
        
        if org:
            extended_parts.append(f"org:{org}")
        if position:
            extended_parts.append(f"pos:{position}")
        
        return "|".join(extended_parts)