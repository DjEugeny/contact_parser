#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ü§ñ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∏—Å–µ–º —Å –≤–ª–æ–∂–µ–Ω–∏—è–º–∏
"""

import json
import re
import os
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

from dotenv import load_dotenv
from email_loader import ProcessedEmailLoader
# from attachment_processor import AttachmentProcessor  # –ê–†–•–ò–í–ò–†–û–í–ê–ù
from ocr_processor_adapter import OCRProcessorAdapter
from llm_extractor import ContactExtractor
from rate_limit_manager import RateLimitManager
from config.regions import calculate_contact_priority

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class IntegratedLLMProcessor:
    """üî• –ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è LLM –∞–Ω–∞–ª–∏–∑–∞ –ø–∏—Å–µ–º + –≤–ª–æ–∂–µ–Ω–∏–π + –ö–ü"""
    
    def __init__(self, test_mode=False):
        self.email_loader = ProcessedEmailLoader()
        self.attachment_processor = OCRProcessorAdapter()
        # –ü–µ—Ä–µ–¥–∞–µ–º test_mode –≤ ContactExtractor –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
        self.contact_extractor = ContactExtractor(test_mode=test_mode)
        self.rate_limit_manager = RateLimitManager()  # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ rate limit
        self.test_mode = test_mode  # –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ LLM –¥–ª—è –¥—Ä—É–≥–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        
        # –ü–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        current_file = Path(__file__)
        project_root = current_file.parent.parent
        self.data_dir = project_root / "data"
        self.results_dir = self.data_dir / "llm_results"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü–∞–ø–∫–∞ —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏
        self.prompts_dir = project_root / "prompts"
        
        # –°—á–µ—Ç—á–∏–∫–∏
        self.stats = {
            'emails_processed': 0,
            'emails_with_contacts': 0,
            'total_contacts_found': 0,
            'emails_with_attachments': 0,
            'attachments_processed': 0,
            'commercial_offers_found': 0,
            'processing_errors': 0,
            'start_time': None,
            'end_time': None
        }
        
        print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ LLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ v2.0")
        print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.results_dir}")

    def _load_prompt(self, filename: str) -> str:
        """üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        
        prompt_path = self.prompts_dir / filename
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                return content
        except FileNotFoundError:
            print(f"‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}")
            return f"ERROR: –ü—Ä–æ–º–ø—Ç {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω"
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞ {filename}: {e}")
            return f"ERROR: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {filename}"

    def _parse_commercial_analysis(self, response_text: str) -> dict:
        """üíº –ü–∞—Ä—Å–∏–Ω–≥ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""
        
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                return result
            else:
                return {"commercial_offer_found": False, "error": "JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ"}
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∞–Ω–∞–ª–∏–∑–∞ –ö–ü: {e}")
            return {"commercial_offer_found": False, "error": f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}"}

    def analyze_commercial_offers(self, combined_text: str, email_metadata: dict) -> dict:
        """üíº –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ö–ü
            co_prompt = self._load_prompt("commercial_offer_analysis.txt")
            
            if "ERROR:" in co_prompt:
                return {"commercial_offer_found": False, "error": "–ü—Ä–æ–º–ø—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"}
            
            print("   üíº –ê–Ω–∞–ª–∏–∑ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
            if not self.contact_extractor.providers or not self.contact_extractor.current_provider:
                return {"commercial_offer_found": False, "error": "LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"}
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            current_provider = self.contact_extractor.providers[self.contact_extractor.current_provider]
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            response = current_provider['client'].chat.completions.create(
                model=current_provider['model'],
                messages=[
                    {"role": "system", "content": co_prompt},
                    {"role": "user", "content": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–º–º–µ—Ä—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —ç—Ç–æ–≥–æ –ø–∏—Å—å–º–∞ –∏ –≤–ª–æ–∂–µ–Ω–∏–π:\n\n{combined_text}"}  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
                ],
                max_tokens=3000,
                temperature=0.1
            )
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            analysis_result = self._parse_commercial_analysis(response.choices[0].message.content)
            
            if analysis_result.get("commercial_offer_found"):
                print("   ‚úÖ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
                self.stats['commercial_offers_found'] += 1
            else:
                print("   üìÑ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            
            return analysis_result
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ö–ü: {e}")
            return {"commercial_offer_found": False, "error": str(e)}

    def process_emails_by_date(self, target_date: str, max_emails: int = None) -> Dict:
        """üìÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∏—Å–µ–º –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
        
        Args:
            target_date (str): –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            max_emails (int, optional): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. 
                                       –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –ø–∏—Å—å–º–∞.
        """
        
        print(f"\nüéØ –û–ë–†–ê–ë–û–¢–ö–ê –ü–ò–°–ï–ú –ó–ê {target_date}")
        print("="*60)
        
        self.stats['start_time'] = datetime.now()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∏—Å—å–º–∞
        emails = self.email_loader.load_emails_by_date(target_date)
        if not emails:
            print(f"‚ùå –ù–µ—Ç –ø–∏—Å–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞ {target_date}")
            return self._create_empty_result(target_date)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏—Å–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        max_emails_to_process = len(emails) if max_emails is None else min(max_emails, len(emails))
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø–∏—Å–µ–º
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–∏—Å–µ–º: {len(emails)}")
        if max_emails is not None:
            print(f"üéØ –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {max_emails_to_process} –ø–∏—Å–µ–º (–ª–∏–º–∏—Ç: {max_emails})")
        else:
            print(f"üéØ –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: –≤—Å–µ {max_emails_to_process} –ø–∏—Å–µ–º")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –ø–∏—Å—å–º–æ
        processed_results = []
        
        for email_idx, email in enumerate(emails, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –ø–∏—Å–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if email_idx > max_emails_to_process:
                print(f"\nüõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {max_emails_to_process} –ø–∏—Å–µ–º")
                break
                
            try:
                print(f"\n{'‚îÄ'*40}")
                print(f"üìß –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∏—Å—å–º–∞ {email_idx}/{max_emails_to_process}")
                print(f"   –û—Ç: {email.get('from', 'N/A')[:50]}...")
                print(f"   –¢–µ–º–∞: {email.get('subject', 'N/A')[:60]}...")
                
                result = self.process_single_email(email)
                if result:
                    processed_results.append(result)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self.stats['emails_processed'] += 1
                    if result.get('contacts'):
                        self.stats['emails_with_contacts'] += 1
                        self.stats['total_contacts_found'] += len(result['contacts'])
                    if result.get('attachments_processed', 0) > 0:
                        self.stats['emails_with_attachments'] += 1
                        self.stats['attachments_processed'] += result['attachments_processed']
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É LLM –∑–∞–ø—Ä–æ—Å–∞–º–∏
                # –ù–µ –¥–µ–ª–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–∏—Å—å–º–∞
                if email_idx < max_emails_to_process:
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∑–∞–¥–µ—Ä–∂–∫–∏
                    request_result = result.get('request_result', 'other_error')
                    self.rate_limit_manager.record_request(request_result)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
                    delay_used = self.rate_limit_manager.wait_if_needed()
                    if delay_used > 0:
                        print(f"   ‚è≥ –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ {delay_used:.1f} —Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è rate limit")
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∏—Å—å–º–∞ {email_idx}: {e}")
                self.stats['processing_errors'] += 1
                continue
        
        self.stats['end_time'] = datetime.now()
        
        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_result = self._create_final_result(target_date, processed_results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self._save_results(target_date, final_result)
        
        # –ü–µ—á–∞—Ç–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._print_final_statistics()
        
        return final_result

    def process_single_email(self, email: Dict) -> Optional[Dict]:
        """üìß –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–∏—Å—å–º–∞ —Å –≤–ª–æ–∂–µ–Ω–∏—è–º–∏ + –∞–Ω–∞–ª–∏–∑ –ö–ü"""
        
        try:
            # 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–∏—è
            attachments_result = self.attachment_processor.process_email_attachments(
                email, self.email_loader
            )
            
            # 2. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –ø–∏—Å—å–º–∞ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –≤–ª–æ–∂–µ–Ω–∏–π
            combined_text = self.attachment_processor.combine_email_with_attachments(
                email, attachments_result
            )
            
            print(f"   üìù –û–±—â–∏–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {len(combined_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   üìé –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–ª–æ–∂–µ–Ω–∏–π: {attachments_result['attachments_processed']}")
            
            # 3. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM
            email_metadata = {
                'from': email.get('from', ''),
                'to': email.get('to', ''),
                'cc': email.get('cc', ''),
                'subject': email.get('subject', ''),
                'date': email.get('date', ''),
                'thread_id': email.get('thread_id', ''),
                'has_attachments': len(email.get('attachments', [])) > 0,
                'attachments_count': len(email.get('attachments', []))
            }
            
            # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã —á–µ—Ä–µ–∑ LLM
            if self.test_mode:
                print("   üß™ –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º LLM –∑–∞–ø—Ä–æ—Å—ã")
                llm_result = {
                    "contacts": [
                        {
                            "name": "–¢–µ—Å—Ç–æ–≤—ã–π –ö–æ–Ω—Ç–∞–∫—Ç",
                            "phone": "+7-999-123-45-67",
                            "email": "test@example.com",
                            "organization": "–¢–µ—Å—Ç–æ–≤–∞—è –ö–æ–º–ø–∞–Ω–∏—è",
                            "position": "–ú–µ–Ω–µ–¥–∂–µ—Ä",
                            "city": "–ú–æ—Å–∫–≤–∞",
                            "confidence": 0.95
                        }
                    ],
                    "business_context": {
                        "topic": "–¢–µ—Å—Ç–æ–≤–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ",
                        "product_interest": "–ê–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã",
                        "communication_stage": "–ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç",
                        "request_type": "–ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                        "urgency": "—Å—Ä–µ–¥–Ω—è—è"
                    },
                    "action_items": [
                        "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
                        "–°–≤—è–∑–∞—Ç—å—Å—è –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É"
                    ]
                }
            else:
                print("   ü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ LLM –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤...")
                llm_result = self.contact_extractor.extract_contacts(combined_text, email_metadata)
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É LLM –∑–∞–ø—Ä–æ—Å–∞–º–∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
            
            # 5. –ù–û–í–û–ï: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if self.test_mode:
                print("   üß™ –¢–ï–°–¢–û–í–´–ô –†–ï–ñ–ò–ú: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –ö–ü")
                commercial_analysis = {
                    "commercial_offer_found": False,
                    "offer_number": "–¢–ï–°–¢-001",
                    "supplier_info": {"company": "–¢–µ—Å—Ç–æ–≤–∞—è –ö–æ–º–ø–∞–Ω–∏—è"},
                    "total_cost": "100000",
                    "currency": "RUB"
                }
            else:
                commercial_analysis = self.analyze_commercial_offers(combined_text, email_metadata)
            
            # 6. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
            if llm_result and isinstance(llm_result, dict):
                for contact in llm_result.get('contacts', []):
                    if contact and isinstance(contact, dict):
                        business_context = llm_result.get('business_context', {}) or {}
                        priority_info = calculate_contact_priority(contact, business_context)
                        contact['priority'] = priority_info
            
            # 7. –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                'original_email': {
                    'thread_id': email.get('thread_id'),
                    'from': email.get('from'),
                    'subject': email.get('subject'),
                    'date': email.get('date'),
                    'json_file_path': email.get('json_file_path')
                },
                'attachments_processed': attachments_result['attachments_processed'],
                'attachments_details': attachments_result['attachments_text'],
                'combined_text_length': len(combined_text),
                'llm_analysis': llm_result,
                'commercial_analysis': commercial_analysis,  # –ù–û–í–û–ï: –¥–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –ö–ü
                'contacts': llm_result.get('contacts', []),
                'business_context': llm_result.get('business_context', {}),
                'action_items': llm_result.get('action_items', []),
                'tags': llm_result.get('tags', []),
                'processed_at': datetime.now().isoformat()
            }
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            contacts_count = len(result['contacts'])
            if contacts_count > 0:
                print(f"   üë• –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {contacts_count}")
                for contact in result['contacts'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2
                    priority = contact.get('priority', {})
                    conf = contact.get('confidence', 0)
                    print(f"      ‚Ä¢ {contact.get('name', 'N/A')} (confidence: {conf}, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority.get('level', 'N/A')})")
            else:
                print(f"   üë§ –ö–æ–Ω—Ç–∞–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –ö–ü
            if commercial_analysis.get('commercial_offer_found'):
                total_cost = commercial_analysis.get('total_cost', 'N/A')
                supplier = commercial_analysis.get('supplier_info', {}).get('company', 'N/A')
                print(f"   üíº –ö–ü –Ω–∞–π–¥–µ–Ω–æ: {total_cost} –æ—Ç {supplier}")
            
            return result
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∏—Å—å–º–∞: {e}")
            return None

    def _normalize_email(self, email: str) -> str:
        """üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è email –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not email:
            return ""
        return email.lower().strip()
    
    def _normalize_phone(self, phone: str) -> str:
        """üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not phone:
            return ""
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ +
        import re
        normalized = re.sub(r'[^\d+]', '', phone)
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É: –µ—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 8, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ +7
        if normalized.startswith('8') and len(normalized) == 11:
            normalized = '+7' + normalized[1:]
        return normalized
    
    def _normalize_name(self, name: str) -> str:
        """üîß –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not name:
            return ""
        return ' '.join(name.lower().strip().split())
    
    def _merge_contact_group(self, contacts: List[Dict]) -> Dict:
        """üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
        if not contacts:
            return {}
        
        if len(contacts) == 1:
            return contacts[0]
        
        print(f"   üîó –û–±—ä–µ–¥–∏–Ω—è—é {len(contacts)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–Ω—Ç–∞–∫—Ç–∞")
        
        # –ë–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–∞–∫—Ç - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π
        merged = contacts[0].copy()
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
        all_phones = set()
        max_confidence = 0
        
        for contact in contacts:
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è, –≤—ã–±–∏—Ä–∞—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            for field in ['name', 'organization', 'position', 'city']:
                current_value = merged.get(field, '')
                new_value = contact.get(field, '')
                
                # –ë–µ—Ä–µ–º –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                if len(str(new_value)) > len(str(current_value)):
                    merged[field] = new_value
            
            # Email –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–µ–ø—É—Å—Ç–æ–π
            if not merged.get('email') and contact.get('email'):
                merged['email'] = contact['email']
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            if contact.get('phone'):
                all_phones.add(contact['phone'])
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π confidence
            contact_conf = contact.get('confidence', 0)
            if contact_conf > max_confidence:
                max_confidence = contact_conf
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if all_phones:
            merged['phone'] = list(all_phones)[0]  # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–ª–µ—Ñ–æ–Ω
            if len(all_phones) > 1:
                merged['other_phones'] = list(all_phones)[1:]  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
        
        merged['confidence'] = max_confidence
        
        return merged
    
    def _deduplicate_contacts(self, contacts: List[Dict]) -> List[Dict]:
        """üîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –ø–æ email, —Ç–µ–ª–µ—Ñ–æ–Ω—É –∏ –∏–º–µ–Ω–∏"""
        if not contacts:
            return []
        
        print(f"   üîç –ù–∞—á–∏–Ω–∞—é –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é {len(contacts)} –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –∫–ª—é—á–∞–º
        groups_by_email = {}
        groups_by_phone = {}
        groups_by_name_org = {}
        processed_contacts = set()
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ email (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1)
        for i, contact in enumerate(contacts):
            email = contact.get('email')
            if email:
                norm_email = self._normalize_email(email)
                if norm_email:
                    if norm_email not in groups_by_email:
                        groups_by_email[norm_email] = []
                    groups_by_email[norm_email].append((i, contact))
                    processed_contacts.add(i)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2)
        for i, contact in enumerate(contacts):
            if i in processed_contacts:
                continue
            
            phone = contact.get('phone')
            if phone:
                norm_phone = self._normalize_phone(phone)
                if norm_phone:
                    if norm_phone not in groups_by_phone:
                        groups_by_phone[norm_phone] = []
                    groups_by_phone[norm_phone].append((i, contact))
                    processed_contacts.add(i)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∏–º–µ–Ω–∏ + –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3)
        for i, contact in enumerate(contacts):
            if i in processed_contacts:
                continue
            
            name = contact.get('name')
            org = contact.get('organization')
            if name and org:
                norm_key = f"{self._normalize_name(name)}|{self._normalize_name(org)}"
                if norm_key not in groups_by_name_org:
                    groups_by_name_org[norm_key] = []
                groups_by_name_org[norm_key].append((i, contact))
                processed_contacts.add(i)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≥—Ä—É–ø–ø—ã –∏ —Å–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        unique_contacts = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã –ø–æ email
        for email, group in groups_by_email.items():
            contacts_in_group = [contact for _, contact in group]
            merged = self._merge_contact_group(contacts_in_group)
            unique_contacts.append(merged)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É
        for phone, group in groups_by_phone.items():
            contacts_in_group = [contact for _, contact in group]
            merged = self._merge_contact_group(contacts_in_group)
            unique_contacts.append(merged)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã –ø–æ –∏–º–µ–Ω–∏+–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        for key, group in groups_by_name_org.items():
            contacts_in_group = [contact for _, contact in group]
            merged = self._merge_contact_group(contacts_in_group)
            unique_contacts.append(merged)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        for i, contact in enumerate(contacts):
            if i not in processed_contacts:
                unique_contacts.append(contact)
        
        duplicates_found = len(contacts) - len(unique_contacts)
        if duplicates_found > 0:
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–æ {duplicates_found} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            print(f"   üìä –ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {len(unique_contacts)}")
        else:
            print(f"   ‚ÑπÔ∏è –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        return unique_contacts
    
    def _create_final_result(self, target_date: str, processed_results: List[Dict]) -> Dict:
        """üìä –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã
        all_contacts = []
        all_business_contexts = []
        all_action_items = []
        all_commercial_offers = []
        
        for result in processed_results:
            all_contacts.extend(result.get('contacts', []))
            if result.get('business_context'):
                all_business_contexts.append(result['business_context'])
            all_action_items.extend(result.get('action_items', []))
            
            # –ù–û–í–û–ï: —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ö–ü
            commercial_analysis = result.get('commercial_analysis', {})
            if commercial_analysis.get('commercial_offer_found'):
                all_commercial_offers.append({
                    'email_thread_id': result.get('original_email', {}).get('thread_id'),
                    'email_from': result.get('original_email', {}).get('from'),
                    'commercial_offer': commercial_analysis
                })
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
        unique_contacts = self._deduplicate_contacts(all_contacts)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ç–∞–∫—Ç—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        contacts_by_priority = {
            'high': [c for c in unique_contacts if c.get('priority', {}).get('score', 0) >= 0.8],
            'medium': [c for c in unique_contacts if 0.6 <= c.get('priority', {}).get('score', 0) < 0.8],
            'low': [c for c in unique_contacts if c.get('priority', {}).get('score', 0) < 0.6]
        }
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Ä–µ–º—è –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ JSON
        processing_time = None
        if self.stats['start_time'] and self.stats['end_time']:
            processing_time = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
            
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ ISO –¥–ª—è JSON
        processed_at = datetime.now().isoformat()
        
        return {
            'processing_date': target_date,
            'processed_at': processed_at,
            'processing_time_seconds': processing_time,
            'statistics': {
                'emails_processed': self.stats['emails_processed'],
                'emails_with_contacts': self.stats['emails_with_contacts'],
                'total_contacts_found': self.stats['total_contacts_found'],
                'emails_with_attachments': self.stats['emails_with_attachments'],
                'attachments_processed': self.stats['attachments_processed'],
                'commercial_offers_found': self.stats['commercial_offers_found'],
                'processing_errors': self.stats['processing_errors']
            },
            'emails_results': processed_results,
            'summary': {
                'total_contacts': len(unique_contacts),
                'contacts_by_priority': {
                    'high': len(contacts_by_priority['high']),
                    'medium': len(contacts_by_priority['medium']),
                    'low': len(contacts_by_priority['low'])
                },
                'total_action_items': len(all_action_items),
                'total_business_contexts': len(all_business_contexts),
                'total_commercial_offers': len(all_commercial_offers)  # –ù–û–í–û–ï
            },
            'all_contacts': unique_contacts,
            'all_action_items': all_action_items,
            'all_commercial_offers': all_commercial_offers,  # –ù–û–í–û–ï
            'high_priority_contacts': contacts_by_priority['high']
        }

    def _create_empty_result(self, target_date: str) -> Dict:
        """üì≠ –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–≥–¥–∞ –Ω–µ—Ç –ø–∏—Å–µ–º"""
        
        return {
            'processing_date': target_date,
            'processed_at': datetime.now().isoformat(),
            'processing_time_seconds': 0,
            'statistics': {'emails_processed': 0, 'errors': 'No emails found'},
            'emails_results': [],
            'summary': {'total_contacts': 0, 'total_action_items': 0, 'total_commercial_offers': 0},
            'all_contacts': [],
            'all_action_items': [],
            'all_commercial_offers': []
        }

    def _save_results(self, target_date: str, results: Dict):
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        results_filename = f"llm_analysis_{target_date.replace('-', '')}.json"
        results_path = self.results_dir / results_filename
        
        try:
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ
            summary_data = {
                'date': target_date,
                'processed_at': results['processed_at'],
                'statistics': results['statistics'],
                'summary': results['summary'],
                'high_priority_contacts_preview': [
                    {
                        'name': c.get('name'),
                        'organization': c.get('organization'), 
                        'city': c.get('city'),
                        'confidence': c.get('confidence'),
                        'priority_score': c.get('priority', {}).get('score')
                    }
                    for c in results['high_priority_contacts'][:5]  # –¢–æ–ø-5
                ],
                'commercial_offers_preview': [  # –ù–û–í–û–ï: –ø—Ä–µ–≤—å—é –ö–ü
                    {
                        'from': co.get('email_from'),
                        'total_cost': co.get('commercial_offer', {}).get('total_cost'),
                        'supplier': co.get('commercial_offer', {}).get('supplier_info', {}).get('company'),
                        'delivery_terms': co.get('commercial_offer', {}).get('delivery_terms')
                    }
                    for co in results.get('all_commercial_offers', [])[:3]  # –¢–æ–ø-3
                ]
            }
            
            summary_path = self.results_dir / f"summary_{target_date.replace('-', '')}.json"
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"üìä –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞: {summary_path}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    def _print_final_statistics(self):
        """üìä –ü–µ—á–∞—Ç—å –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        
        print(f"\n{'='*60}")
        print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print(f"{'='*60}")
        
        print(f"üìß –ü–∏—Å–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['emails_processed']}")
        print(f"üë• –ü–∏—Å–µ–º —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º–∏: {self.stats['emails_with_contacts']}")
        print(f"üéØ –í—Å–µ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {self.stats['total_contacts_found']}")
        print(f"üìé –ü–∏—Å–µ–º —Å –≤–ª–æ–∂–µ–Ω–∏—è–º–∏: {self.stats['emails_with_attachments']}")
        print(f"üìé –í–ª–æ–∂–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['attachments_processed']}")
        print(f"üíº –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {self.stats['commercial_offers_found']}")  # –ù–û–í–û–ï
        print(f"‚ùå –û—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.stats['processing_errors']}")
        
        if self.stats['start_time'] and self.stats['end_time']:
            processing_time = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.1f} —Å–µ–∫—É–Ω–¥")
            
            if self.stats['emails_processed'] > 0:
                avg_time = processing_time / self.stats['emails_processed']
                print(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –ø–∏—Å—å–º–æ: {avg_time:.1f} —Å–µ–∫—É–Ω–¥")
        
        print(f"{'='*60}")

def main():
    """üöÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    
    print("ü§ñ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ì–û LLM –ü–†–û–¶–ï–°–°–û–†–ê")
    print("="*70)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ (–±–µ–∑ LLM –∑–∞–ø—Ä–æ—Å–æ–≤)
    processor = IntegratedLLMProcessor(test_mode=True)
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç—ã
    available_dates = processor.email_loader.get_available_date_folders()
    
    if not available_dates:
        print("‚ùå –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∏—Å–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ advanced_email_fetcher.py")
        return
    
    print(f"üìÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç—ã: {available_dates}")
    
    # –í—ã–±–∏—Ä–∞–µ–º –¥–∞—Ç—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∏—Å–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    target_date = "2025-07-29"  # –î–∞—Ç–∞ —Å 30 –ø–∏—Å—å–º–∞–º–∏
    print(f"üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –¥–∞—Ç–µ: {target_date}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    results = processor.process_emails_by_date(target_date)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if results and results['summary']['total_contacts'] > 0:
        print(f"\nüèÜ –¢–û–ü –ù–ê–ô–î–ï–ù–ù–´–ï –ö–û–ù–¢–ê–ö–¢–´:")
        for contact_idx, contact in enumerate(results.get('high_priority_contacts', [])[:3], 1):
            priority = contact.get('priority', {})
            print(f"   {contact_idx}. {contact.get('name', 'N/A')} ({contact.get('organization', 'N/A')})")
            print(f"      –ì–æ—Ä–æ–¥: {contact.get('city', 'N/A')}, Confidence: {contact.get('confidence', 0)}")
            print(f"      –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority.get('level', 'N/A')} (score: {priority.get('score', 0)})")
    
    print(f"\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è Sprint 3 (Google Sheets)!")


if __name__ == '__main__':
    main()
