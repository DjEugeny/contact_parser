#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ñ–∞–π–ª–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –¥–∞—Ç–∞–º
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –≤–æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
"""

import os
import re
from pathlib import Path
from datetime import datetime
from src.file_utils import normalize_filename

# –§—É–Ω–∫—Ü–∏—è normalize_filename –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑ src.file_utils

def analyze_date_folder(date_str):
    """–ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¥–∞—Ç—ã"""
    print(f"\n{'='*80}")
    print(f"–ê–ù–ê–õ–ò–ó –î–ê–¢–´: {date_str}")
    print(f"{'='*80}")
    
    attachments_path = f"/Users/evgenyzach/contact_parser/data/attachments/{date_str}"
    results_path = f"/Users/evgenyzach/contact_parser/data/final_results/texts/{date_str}"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫
    attachments_exists = os.path.exists(attachments_path)
    results_exists = os.path.exists(results_path)
    
    print(f"üìÅ –ü–∞–ø–∫–∞ –≤–ª–æ–∂–µ–Ω–∏–π: {attachments_path}")
    print(f"   –°—É—â–µ—Å—Ç–≤—É–µ—Ç: {'‚úÖ' if attachments_exists else '‚ùå'}")
    
    print(f"üìÅ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {results_path}")
    print(f"   –°—É—â–µ—Å—Ç–≤—É–µ—Ç: {'‚úÖ' if results_exists else '‚ùå'}")
    
    if not attachments_exists:
        print("‚ö†Ô∏è  –ü–†–û–ë–õ–ï–ú–ê: –ü–∞–ø–∫–∞ –≤–ª–æ–∂–µ–Ω–∏–π –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤–æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö
    attachment_files = []
    for ext in ['*.pdf', '*.docx', '*.doc']:
        attachment_files.extend(Path(attachments_path).glob(ext))
    
    attachment_names = [f.name for f in attachment_files]
    attachment_count = len(attachment_names)
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –§–∞–π–ª–æ–≤ –≤–æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö: {attachment_count}")
    
    if results_exists:
        result_files = list(Path(results_path).glob('*.txt'))
        result_count = len(result_files)
        print(f"   –§–∞–π–ª–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö: {result_count}")
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {attachment_count - result_count}")
    else:
        result_files = []
        result_count = 0
        print(f"   –§–∞–π–ª–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö: 0 (–ø–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)")
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {attachment_count}")
    
    # –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∏–º–µ–Ω–∞–º
    normalized_map = {}
    for filename in attachment_names:
        normalized = normalize_filename(filename)
        if normalized not in normalized_map:
            normalized_map[normalized] = []
        normalized_map[normalized].append(filename)
    
    duplicates = {k: v for k, v in normalized_map.items() if len(v) > 1}
    unique_normalized_count = len(normalized_map)
    
    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏–º–µ–Ω: {unique_normalized_count}")
    print(f"   –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–∞—Ö
    print(f"\nüìã –°–ü–ò–°–û–ö –§–ê–ô–õ–û–í –í–û –í–õ–û–ñ–ï–ù–ò–Ø–•:")
    for i, filename in enumerate(attachment_names, 1):
        normalized = normalize_filename(filename)
        is_duplicate = len(normalized_map[normalized]) > 1
        duplicate_marker = " üîÑ [–î–£–ë–õ–ò–ö–ê–¢]" if is_duplicate else ""
        print(f"   {i:2d}. {filename}{duplicate_marker}")
        print(f"       –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ: {normalized}")
    
    if duplicates:
        print(f"\nüîÑ –ì–†–£–ü–ü–´ –î–£–ë–õ–ò–ö–ê–¢–û–í:")
        for normalized, files in duplicates.items():
            print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è: {normalized}")
            for file in files:
                print(f"     - {file}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if results_exists and result_files:
        print(f"\nüìÑ –§–ê–ô–õ–´ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        result_names = [f.stem for f in result_files]
        for i, name in enumerate(result_names, 1):
            print(f"   {i:2d}. {name}.txt")
        
        # –ü–æ–∏—Å–∫ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        processed_normalized = set()
        for result_name in result_names:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
            for normalized, original_files in normalized_map.items():
                if normalized in result_name or result_name in normalized:
                    processed_normalized.add(normalized)
                    break
        
        unprocessed_normalized = set(normalized_map.keys()) - processed_normalized
        
        if unprocessed_normalized:
            print(f"\n‚ùå –ù–ï–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –§–ê–ô–õ–´ (–ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∏–º–µ–Ω–∞–º):")
            for normalized in unprocessed_normalized:
                original_files = normalized_map[normalized]
                print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ: {normalized}")
                for file in original_files:
                    print(f"     - {file}")
        else:
            print(f"\n‚úÖ –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if attachment_count == 0:
        print(f"   - –ü–∞–ø–∫–∞ –≤–ª–æ–∂–µ–Ω–∏–π –ø—É—Å—Ç–∞")
    elif not results_exists:
        print(f"   - –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —ç—Ç–æ–π –¥–∞—Ç—ã")
    elif result_count == 0:
        print(f"   - –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—É—Å—Ç–∞, –≤–æ–∑–º–æ–∂–Ω—ã –æ—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    elif result_count < unique_normalized_count:
        print(f"   - –ù–µ –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
        print(f"   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –æ—à–∏–±–∫–∏")
    elif duplicates:
        print(f"   - –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤")
        print(f"   - OCR –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö –∫–∞–∫ –æ–¥–∏–Ω —Ñ–∞–π–ª")
    else:
        print(f"   - –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–≥–ª—è–¥–∏—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú –û–ë–†–ê–ë–û–¢–ö–ò –§–ê–ô–õ–û–í")
    print(f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    problem_dates = [
        "2025-08-25",  # 10 —Ñ–∞–π–ª–æ–≤ -> 8 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        "2025-07-15",  # 7 —Ñ–∞–π–ª–æ–≤ -> 6 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤  
        "2025-08-15",  # 7 —Ñ–∞–π–ª–æ–≤ -> 6 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        "2025-08-20",  # 9 —Ñ–∞–π–ª–æ–≤, 1 —Å –æ—à–∏–±–∫–∞–º–∏
        "2025-07-11",  # 1 —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω
    ]
    
    for date_str in problem_dates:
        analyze_date_folder(date_str)
    
    print(f"\n{'='*80}")
    print("–û–ë–©–ò–ï –í–´–í–û–î–´:")
    print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –Ω–∞ –æ—à–∏–±–∫–∏")
    print("2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤")
    print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞–ø–∫–∞–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()