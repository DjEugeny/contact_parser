#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–≥–æ–≤ OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
–í—ã—è–≤–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
"""

import os
import re
from pathlib import Path
from datetime import datetime
import json

def find_log_files():
    """–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤ OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    log_patterns = [
        "/Users/evgenyzach/contact_parser/logs/*.log",
        "/Users/evgenyzach/contact_parser/*.log", 
        "/Users/evgenyzach/contact_parser/data/logs/*.log",
        "/Users/evgenyzach/contact_parser/ocr_processor.log",
        "/Users/evgenyzach/contact_parser/processing.log"
    ]
    
    log_files = []
    for pattern in log_patterns:
        if '*' in pattern:
            log_files.extend(Path(pattern.split('*')[0]).glob('*.log'))
        else:
            if os.path.exists(pattern):
                log_files.append(Path(pattern))
    
    return log_files

def analyze_log_file(log_path, target_dates=None):
    """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–æ–≥ —Ñ–∞–π–ª–∞"""
    print(f"\nüìÑ –ê–ù–ê–õ–ò–ó –õ–û–ì–ê: {log_path}")
    
    if not os.path.exists(log_path):
        print(f"   ‚ùå –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return
    
    lines = content.split('\n')
    print(f"   üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ –ª–æ–≥–µ: {len(lines)}")
    
    # –ü–æ–∏—Å–∫ –æ—à–∏–±–æ–∫
    error_patterns = [
        r'ERROR',
        r'CRITICAL', 
        r'Exception',
        r'Traceback',
        r'Failed',
        r'Error processing',
        r'Could not process',
        r'Unable to',
        r'timeout',
        r'connection.*error',
        r'permission.*denied'
    ]
    
    errors_found = []
    for i, line in enumerate(lines):
        for pattern in error_patterns:
            if re.search(pattern, line, re.IGNORECASE):
                errors_found.append((i+1, line.strip()))
                break
    
    print(f"   üö® –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {len(errors_found)}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–∞—Ç–∞–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
    if target_dates:
        print(f"\n   üéØ –ê–ù–ê–õ–ò–ó –ü–û –¶–ï–õ–ï–í–´–ú –î–ê–¢–ê–ú: {', '.join(target_dates)}")
        for date_str in target_dates:
            date_errors = []
            for line_num, line in errors_found:
                if date_str in line:
                    date_errors.append((line_num, line))
            
            print(f"\n   üìÖ –î–∞—Ç–∞ {date_str}:")
            if date_errors:
                print(f"      üö® –û—à–∏–±–æ–∫: {len(date_errors)}")
                for line_num, line in date_errors[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    print(f"      {line_num:4d}: {line[:100]}...")
            else:
                print(f"      ‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—à–∏–±–∫–∏
    if errors_found:
        print(f"\n   üîç –ü–û–°–õ–ï–î–ù–ò–ï –û–®–ò–ë–ö–ò (–¥–æ 10):")
        for line_num, line in errors_found[-10:]:
            print(f"      {line_num:4d}: {line[:150]}")
    
    # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–∞—Ö
    file_processing_patterns = [
        r'Processing file.*?([\w\-\.]+\.(pdf|docx|doc))',
        r'–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞.*?([\w\-\.]+\.(pdf|docx|doc))',
        r'File processed.*?([\w\-\.]+\.(pdf|docx|doc))',
        r'–§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω.*?([\w\-\.]+\.(pdf|docx|doc))'
    ]
    
    processed_files = set()
    for line in lines:
        for pattern in file_processing_patterns:
            matches = re.findall(pattern, line, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    processed_files.add(match[0])
                else:
                    processed_files.add(match)
    
    print(f"\n   üìÅ –§–∞–π–ª–æ–≤ –≤ –ª–æ–≥–µ: {len(processed_files)}")
    if processed_files and len(processed_files) <= 20:
        for file in sorted(processed_files):
            print(f"      - {file}")

def check_recent_terminal_output():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–∞–≤–Ω–µ–≥–æ –≤—ã–≤–æ–¥–∞ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"""
    print(f"\nüñ•Ô∏è  –ü–†–û–í–ï–†–ö–ê –ù–ï–î–ê–í–ù–ï–ô –ê–ö–¢–ò–í–ù–û–°–¢–ò –¢–ï–†–ú–ò–ù–ê–õ–ê")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –∫–æ–º–∞–Ω–¥
    history_file = os.path.expanduser("~/.zsh_history")
    if os.path.exists(history_file):
        try:
            with open(history_file, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # –ò—â–µ–º –∫–æ–º–∞–Ω–¥—ã —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å OCR
            ocr_commands = []
            for line in lines[-100:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∫–æ–º–∞–Ω–¥
                if any(keyword in line.lower() for keyword in ['ocr', 'process', 'python', 'contact_parser']):
                    ocr_commands.append(line.strip())
            
            print(f"   üìä –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥: {len(ocr_commands)}")
            if ocr_commands:
                print(f"   üîç –ü–û–°–õ–ï–î–ù–ò–ï –ö–û–ú–ê–ù–î–´:")
                for cmd in ocr_commands[-5:]:
                    print(f"      {cmd}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é: {e}")
    else:
        print(f"   ‚ùå –§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")

def analyze_file_structure():
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"""
    print(f"\nüìÅ –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê")
    
    base_path = "/Users/evgenyzach/contact_parser"
    
    # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    key_files = [
        "ocr_processor.py",
        "integrated_llm_processor.py", 
        "main.py",
        "run_ocr.py",
        "config.py"
    ]
    
    print(f"   üîç –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ô–õ–´:")
    for file in key_files:
        file_path = os.path.join(base_path, file)
        exists = os.path.exists(file_path)
        if exists:
            stat = os.stat(file_path)
            size = stat.st_size
            mtime = datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M')
            print(f"      ‚úÖ {file} ({size} bytes, –∏–∑–º–µ–Ω–µ–Ω: {mtime})")
        else:
            print(f"      ‚ùå {file} - –ù–ï –ù–ê–ô–î–ï–ù")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–æ–∫ –¥–∞–Ω–Ω—ã—Ö
    data_folders = [
        "data/attachments",
        "data/final_results/texts",
        "data/logs",
        "logs"
    ]
    
    print(f"\n   üìÇ –ü–ê–ü–ö–ò –î–ê–ù–ù–´–•:")
    for folder in data_folders:
        folder_path = os.path.join(base_path, folder)
        exists = os.path.exists(folder_path)
        if exists:
            try:
                items = len(os.listdir(folder_path))
                print(f"      ‚úÖ {folder} ({items} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
            except:
                print(f"      ‚ö†Ô∏è  {folder} (–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞)")
        else:
            print(f"      ‚ùå {folder} - –ù–ï –ù–ê–ô–î–ï–ù–ê")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –õ–û–ì–û–í OCR –ü–†–û–¶–ï–°–°–û–†–ê")
    print(f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞—Ç—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    problem_dates = [
        "2025-08-25",
        "2025-07-15", 
        "2025-08-15",
        "2025-08-20",
        "2025-07-11"
    ]
    
    # –ü–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑ –ª–æ–≥ —Ñ–∞–π–ª–æ–≤
    log_files = find_log_files()
    
    print(f"\nüìÑ –ù–ê–ô–î–ï–ù–û –õ–û–ì –§–ê–ô–õ–û–í: {len(log_files)}")
    
    if log_files:
        for log_file in log_files:
            analyze_log_file(log_file, problem_dates)
    else:
        print("   ‚ùå –õ–æ–≥ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("   üí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("      - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
        print("      - –õ–æ–≥–∏ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ –¥—Ä—É–≥–æ–µ –º–µ—Å—Ç–æ")
        print("      - –õ–æ–≥–∏ –æ—á–∏—â–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    check_recent_terminal_output()
    analyze_file_structure()
    
    print(f"\n{'='*80}")
    print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –î–ò–ê–ì–ù–û–°–¢–ò–ö–ï:")
    print("1. –í–∫–ª—é—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ OCR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ")
    print("2. –î–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ —Å –ø–æ–ª–Ω—ã–º–∏ —Ç—Ä–µ–π—Å–±–µ–∫–∞–º–∏")
    print("3. –õ–æ–≥–∏—Ä—É–π—Ç–µ –∫–∞–∂–¥—ã–π —ç—Ç–∞–ø –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞")
    print("4. –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("5. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é —Ç–∞–±–ª–∏—Ü—É –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()